{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-26T21:45:43.910412Z",
     "iopub.status.busy": "2025-02-26T21:45:43.910111Z",
     "iopub.status.idle": "2025-02-26T21:45:44.928851Z",
     "shell.execute_reply": "2025-02-26T21:45:44.927960Z",
     "shell.execute_reply.started": "2025-02-26T21:45:43.910364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:45:44.930411Z",
     "iopub.status.busy": "2025-02-26T21:45:44.929916Z",
     "iopub.status.idle": "2025-02-26T21:47:05.034306Z",
     "shell.execute_reply": "2025-02-26T21:47:05.033229Z",
     "shell.execute_reply.started": "2025-02-26T21:45:44.930376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Before proceeding run this cell (but if you have already install then ignore)\n",
    "!pip install tensorflow==2.15.0\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n",
    "!pip install wordcloud\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:05.035754Z",
     "iopub.status.busy": "2025-02-26T21:47:05.035414Z",
     "iopub.status.idle": "2025-02-26T21:47:11.651496Z",
     "shell.execute_reply": "2025-02-26T21:47:11.650570Z",
     "shell.execute_reply.started": "2025-02-26T21:47:05.035722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dl packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# ml packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:11.652942Z",
     "iopub.status.busy": "2025-02-26T21:47:11.652413Z",
     "iopub.status.idle": "2025-02-26T21:47:11.725242Z",
     "shell.execute_reply": "2025-02-26T21:47:11.724519Z",
     "shell.execute_reply.started": "2025-02-26T21:47:11.652917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/human-recognition-file/train.txt\", header=None, sep=\";\", names=[\"Comment\", \"Emotion\"], encoding=\"utf-8\")\n",
    "# get all words length in comment\n",
    "train_data['length'] = [len(x) for x in train_data['Comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:11.726486Z",
     "iopub.status.busy": "2025-02-26T21:47:11.726169Z",
     "iopub.status.idle": "2025-02-26T21:47:11.743098Z",
     "shell.execute_reply": "2025-02-26T21:47:11.741896Z",
     "shell.execute_reply.started": "2025-02-26T21:47:11.726436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:11.746096Z",
     "iopub.status.busy": "2025-02-26T21:47:11.745874Z",
     "iopub.status.idle": "2025-02-26T21:47:11.753684Z",
     "shell.execute_reply": "2025-02-26T21:47:11.753015Z",
     "shell.execute_reply.started": "2025-02-26T21:47:11.746077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:11.754930Z",
     "iopub.status.busy": "2025-02-26T21:47:11.754632Z",
     "iopub.status.idle": "2025-02-26T21:47:11.773933Z",
     "shell.execute_reply": "2025-02-26T21:47:11.773159Z",
     "shell.execute_reply.started": "2025-02-26T21:47:11.754907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:11.775169Z",
     "iopub.status.busy": "2025-02-26T21:47:11.774838Z",
     "iopub.status.idle": "2025-02-26T21:47:11.790187Z",
     "shell.execute_reply": "2025-02-26T21:47:11.789373Z",
     "shell.execute_reply.started": "2025-02-26T21:47:11.775137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:11.791385Z",
     "iopub.status.busy": "2025-02-26T21:47:11.791035Z",
     "iopub.status.idle": "2025-02-26T21:47:12.000537Z",
     "shell.execute_reply": "2025-02-26T21:47:11.999652Z",
     "shell.execute_reply.started": "2025-02-26T21:47:11.791353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x = train_data['Emotion'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:12.001964Z",
     "iopub.status.busy": "2025-02-26T21:47:12.001625Z",
     "iopub.status.idle": "2025-02-26T21:47:12.674334Z",
     "shell.execute_reply": "2025-02-26T21:47:12.673300Z",
     "shell.execute_reply.started": "2025-02-26T21:47:12.001931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data distribution\n",
    "df2 = train_data.copy()\n",
    "df2['length'] = [len(x) for x in df2['Comment']]\n",
    "\n",
    "# Convert the 'length' column to a numpy array\n",
    "length_values = df2['length'].values\n",
    "\n",
    "# Use sns.histplot instead of sns.kdeplot for simplicity\n",
    "sns.histplot(data=df2, x='length', hue='Emotion', multiple='stack')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:12.675848Z",
     "iopub.status.busy": "2025-02-26T21:47:12.675486Z",
     "iopub.status.idle": "2025-02-26T21:47:19.631768Z",
     "shell.execute_reply": "2025-02-26T21:47:19.630826Z",
     "shell.execute_reply.started": "2025-02-26T21:47:12.675814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Words cloud for each emotions\n",
    "def words_cloud(wordcloud, df):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(df+' Word Cloud', size = 16)\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");\n",
    "emotions_list = train_data['Emotion'].unique()\n",
    "for emotion in emotions_list:\n",
    "    text = ' '.join([sentence for sentence in train_data.loc[train_data['Emotion'] == emotion,'Comment']])\n",
    "    wordcloud = WordCloud(width = 600, height = 600).generate(text)\n",
    "    words_cloud(wordcloud, emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode emotions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LabelEncoder is transforming the 'Emotion' column in the train_data DataFrame from categorical text values (like \"happy\", \"sad\", \"angry\", etc.) into numerical values.\n",
    "\n",
    "Here’s a step-by-step breakdown of what’s happening:\n",
    "\n",
    "lb = LabelEncoder():\n",
    "\n",
    "This initializes a new instance of the LabelEncoder class.\n",
    "lb.fit_transform(train_data['Emotion']):\n",
    "\n",
    "fit_transform does two things:\n",
    "fit(): It learns all the unique values (or categories) in the 'Emotion' column.\n",
    "transform(): It converts these unique categories into numeric labels (starting from 0) based on their frequency of occurrence or alphabetical order.\n",
    "\n",
    "The LabelEncoder will assign a number to each unique emotion.\n",
    "\"happy\" might get encoded as 1\n",
    "\"sad\" as 2\n",
    "\"angry\" as 0\n",
    "The order of the encoding depends on the alphabetical order of the unique values by default.\n",
    "train_data['Emotion'] = ...:\n",
    "\n",
    "This step assigns the transformed numerical values back to the 'Emotion' column in the train_data DataFrame, replacing the original text values with the encoded numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:19.633165Z",
     "iopub.status.busy": "2025-02-26T21:47:19.632844Z",
     "iopub.status.idle": "2025-02-26T21:47:19.643379Z",
     "shell.execute_reply": "2025-02-26T21:47:19.642544Z",
     "shell.execute_reply.started": "2025-02-26T21:47:19.633137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "train_data['Emotion'] = lb.fit_transform(train_data['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:19.644287Z",
     "iopub.status.busy": "2025-02-26T21:47:19.644101Z",
     "iopub.status.idle": "2025-02-26T21:47:19.670420Z",
     "shell.execute_reply": "2025-02-26T21:47:19.669597Z",
     "shell.execute_reply.started": "2025-02-26T21:47:19.644271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now coming to the Machine Learning Part where we apply multiple Machine Learning algorithms to get the best fit for our problem statement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:19.671598Z",
     "iopub.status.busy": "2025-02-26T21:47:19.671304Z",
     "iopub.status.idle": "2025-02-26T21:47:19.899940Z",
     "shell.execute_reply": "2025-02-26T21:47:19.899276Z",
     "shell.execute_reply.started": "2025-02-26T21:47:19.671578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:39.343833Z",
     "iopub.status.busy": "2025-02-26T21:47:39.343501Z",
     "iopub.status.idle": "2025-02-26T21:47:39.349250Z",
     "shell.execute_reply": "2025-02-26T21:47:39.348265Z",
     "shell.execute_reply.started": "2025-02-26T21:47:39.343812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = train_data.copy() # copy df from train_data because we will use this for deep learing next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:47:42.957311Z",
     "iopub.status.busy": "2025-02-26T21:47:42.957011Z",
     "iopub.status.idle": "2025-02-26T21:47:42.966370Z",
     "shell.execute_reply": "2025-02-26T21:47:42.965529Z",
     "shell.execute_reply.started": "2025-02-26T21:47:42.957292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:48:01.837849Z",
     "iopub.status.busy": "2025-02-26T21:48:01.837565Z",
     "iopub.status.idle": "2025-02-26T21:48:04.611009Z",
     "shell.execute_reply": "2025-02-26T21:48:04.610316Z",
     "shell.execute_reply.started": "2025-02-26T21:48:01.837828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords]\n",
    "    return \" \".join(text)\n",
    "\n",
    "df['cleaned_comment'] = df['Comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:48:08.147987Z",
     "iopub.status.busy": "2025-02-26T21:48:08.147684Z",
     "iopub.status.idle": "2025-02-26T21:48:08.155160Z",
     "shell.execute_reply": "2025-02-26T21:48:08.154353Z",
     "shell.execute_reply.started": "2025-02-26T21:48:08.147964Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_comment'],df['Emotion'],test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:48:15.758153Z",
     "iopub.status.busy": "2025-02-26T21:48:15.757819Z",
     "iopub.status.idle": "2025-02-26T21:48:15.913848Z",
     "shell.execute_reply": "2025-02-26T21:48:15.913183Z",
     "shell.execute_reply.started": "2025-02-26T21:48:15.758131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Vectorization using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:48:34.837154Z",
     "iopub.status.busy": "2025-02-26T21:48:34.836868Z",
     "iopub.status.idle": "2025-02-26T21:49:21.615604Z",
     "shell.execute_reply": "2025-02-26T21:49:21.614735Z",
     "shell.execute_reply.started": "2025-02-26T21:48:34.837134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Multi-class classification using different algorithms\n",
    "classifiers = {\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred_tfidf = clf.predict(X_test_tfidf)\n",
    "    accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "    print(f\"\\nAccuracy using TF-IDF: {accuracy_tfidf}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:49:22.476923Z",
     "iopub.status.busy": "2025-02-26T21:49:22.476665Z",
     "iopub.status.idle": "2025-02-26T21:49:23.291636Z",
     "shell.execute_reply": "2025-02-26T21:49:23.290714Z",
     "shell.execute_reply.started": "2025-02-26T21:49:22.476902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# selecting model\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train_tfidf, y_train)\n",
    "lg_y_pred = lg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:49:29.659430Z",
     "iopub.status.busy": "2025-02-26T21:49:29.659145Z",
     "iopub.status.idle": "2025-02-26T21:49:29.691015Z",
     "shell.execute_reply": "2025-02-26T21:49:29.690386Z",
     "shell.execute_reply.started": "2025-02-26T21:49:29.659409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_emotion(input_text):\n",
    "    cleaned_text = clean_text(input_text)\n",
    "    input_vectorized = tfidf_vectorizer.transform([cleaned_text])\n",
    "\n",
    "    # Predict emotion\n",
    "    predicted_label = lg.predict(input_vectorized)[0]\n",
    "    predicted_emotion = lb.inverse_transform([predicted_label])[0]\n",
    "    label =  np.max(lg.predict(input_vectorized))\n",
    "\n",
    "    return predicted_emotion,label\n",
    "\n",
    "# Example usage \n",
    "sentences = [\n",
    "            \"i didnt feel humiliated\",\n",
    "            \"i feel strong and good overall\",\n",
    "            \"im grabbing a minute to post i feel greedy wrong\",\n",
    "            \"He was speechles when he found out he was accepted to this new job\",\n",
    "            \"This is outrageous, how can you talk like that?\",\n",
    "            \"I feel like im all alone in this world\",\n",
    "            \"He is really sweet and caring\",\n",
    "            \"You made me very crazy\",\n",
    "            \"i am ever feeling nostalgic about the fireplace i will know that it is still on the property\",\n",
    "            \"i am feeling grouchy\",\n",
    "            \"He hates you\"\n",
    "            ]\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    pred_emotion, label = predict_emotion(sentence)\n",
    "    print(\"Prediction :\",pred_emotion)\n",
    "    print(\"Label :\",label)\n",
    "    print(\"================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `label` represents the highest predicted confidence score or probability of the predicted emotion class, indicating the model's certainty in its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:56:08.098686Z",
     "iopub.status.busy": "2025-02-26T21:56:08.098314Z",
     "iopub.status.idle": "2025-02-26T21:56:08.107439Z",
     "shell.execute_reply": "2025-02-26T21:56:08.106567Z",
     "shell.execute_reply.started": "2025-02-26T21:56:08.098662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save files\n",
    "import pickle\n",
    "pickle.dump(lg,open(\"logistic_regresion.pkl\",'wb'))\n",
    "pickle.dump(lb,open(\"label_encoder.pkl\",'wb'))\n",
    "pickle.dump(tfidf_vectorizer,open(\"tfidf_vectorizer.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T21:56:38.055743Z",
     "iopub.status.busy": "2025-02-26T21:56:38.055372Z",
     "iopub.status.idle": "2025-02-26T21:56:38.060191Z",
     "shell.execute_reply": "2025-02-26T21:56:38.059418Z",
     "shell.execute_reply.started": "2025-02-26T21:56:38.055716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__) # use this version in pycharm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will apply Deep Learning using LSTM( Long Short-Term Memory).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Cleaning, Ecoding, and Padding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T22:00:28.932333Z",
     "iopub.status.busy": "2025-02-26T22:00:28.931988Z",
     "iopub.status.idle": "2025-02-26T22:00:32.112434Z",
     "shell.execute_reply": "2025-02-26T22:00:32.111543Z",
     "shell.execute_reply.started": "2025-02-26T22:00:28.932308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def text_cleaning(df, column, vocab_size, max_len):\n",
    "    stemmer = PorterStemmer()\n",
    "    corpus = []\n",
    "\n",
    "    for text in df[column]:\n",
    "        text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        text = text.lower()\n",
    "        text = text.split()\n",
    "        text = [stemmer.stem(word) for word in text if word not in stopwords]\n",
    "        text = \" \".join(text)\n",
    "        corpus.append(text)\n",
    "\n",
    "    one_hot_word = [one_hot(input_text=word, n=vocab_size) for word in corpus]\n",
    "    pad = pad_sequences(sequences=one_hot_word, maxlen=max_len, padding='pre')\n",
    "    return pad\n",
    "\n",
    "# Text cleaning and encoding\n",
    "x_train = text_cleaning(train_data, \"Comment\", vocab_size=11000, max_len=300)\n",
    "y_train = to_categorical(train_data[\"Emotion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Building and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T22:01:20.595425Z",
     "iopub.status.busy": "2025-02-26T22:01:20.595086Z",
     "iopub.status.idle": "2025-02-26T22:02:39.635382Z",
     "shell.execute_reply": "2025-02-26T22:02:39.634742Z",
     "shell.execute_reply.started": "2025-02-26T22:01:20.595399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=11000, output_dim=150, input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "callback = EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T22:02:48.481670Z",
     "iopub.status.busy": "2025-02-26T22:02:48.481315Z",
     "iopub.status.idle": "2025-02-26T22:02:49.989190Z",
     "shell.execute_reply": "2025-02-26T22:02:49.988530Z",
     "shell.execute_reply.started": "2025-02-26T22:02:48.481639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def sentence_cleaning(sentence):\n",
    "    stemmer = PorterStemmer()\n",
    "    corpus = []\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords]\n",
    "    text = \" \".join(text)\n",
    "    corpus.append(text)\n",
    "    one_hot_word = [one_hot(input_text=word, n=11000) for word in corpus]\n",
    "    pad = pad_sequences(sequences=one_hot_word, maxlen=300, padding='pre')\n",
    "    return pad\n",
    "\n",
    "# load model and predict \n",
    "sentences = [\n",
    "            \"i feel strong and good overall\",\n",
    "            \"im grabbing a minute to post i feel greedy wrong\",\n",
    "            \"He was speechles when he found out he was accepted to this new job\",\n",
    "            \"This is outrageous, how can you talk like that?\",\n",
    "            \"I feel like im all alone in this world\",\n",
    "            \"He is really sweet and caring\",\n",
    "            \"You made me very crazy\",\n",
    "            \"i am ever feeling nostalgic about the fireplace i will know that it is still on the property\",\n",
    "            \"i am feeling grouchy\",\n",
    "            \"He hates you\"\n",
    "            ]\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    sentence = sentence_cleaning(sentence)\n",
    "    result = lb.inverse_transform(np.argmax(model.predict(sentence), axis=-1))[0]\n",
    "    proba =  np.max(model.predict(sentence))\n",
    "    print(f\"{result} : {proba}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the model and files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T22:05:22.980917Z",
     "iopub.status.busy": "2025-02-26T22:05:22.980560Z",
     "iopub.status.idle": "2025-02-26T22:05:23.056537Z",
     "shell.execute_reply": "2025-02-26T22:05:23.055607Z",
     "shell.execute_reply.started": "2025-02-26T22:05:22.980894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('model1.h5')\n",
    "\n",
    "# Save the LabelEncoder\n",
    "with open('lb1.pkl', 'wb') as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "# Save vocabulary size and max length\n",
    "vocab_info = {'vocab_size': 11000, 'max_len': 300}\n",
    "with open('vocab_info.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T22:05:41.588710Z",
     "iopub.status.busy": "2025-02-26T22:05:41.588356Z",
     "iopub.status.idle": "2025-02-26T22:05:41.593317Z",
     "shell.execute_reply": "2025-02-26T22:05:41.592573Z",
     "shell.execute_reply.started": "2025-02-26T22:05:41.588684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# use this version\n",
    "import tensorflow\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6749379,
     "sourceId": 10864334,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
